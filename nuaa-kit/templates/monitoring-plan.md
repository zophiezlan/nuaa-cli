# Program Monitoring Plan

**Program Name**: [Name]
**Monitoring Period**: [Start Date] to [End Date]
**Version**: [Number]
**Last Updated**: [Date]
**Monitoring Lead**: [Name, Role]

---

## 1. Purpose of Monitoring

**What is Program Monitoring?**

Monitoring is the ongoing tracking of program activities, outputs, and progress toward objectives. It's different from evaluation (which measures outcomes and impact) - monitoring focuses on *implementation*.

**Why Monitor?**

- Track progress toward targets
- Identify and address problems early
- Support continuous improvement
- Ensure accountability to funders and community
- Provide data for reporting and evaluation

---

## 2. What We're Monitoring

### Logic Model Review

**Inputs → Activities → Outputs → Outcomes → Impact**

**Monitoring focuses on**: Inputs, Activities, and Outputs
**Evaluation focuses on**: Outcomes and Impact

[Reference to logic-model.md or program-design.md for full logic model]

---

### Key Monitoring Areas

#### 1. **Reach & Recruitment**

**What**: Who and how many are accessing the program

**Indicators**:

- Number of participants registered
- Number of unique participants engaged
- Demographic profile of participants
- Recruitment source (how people heard about program)

**Why it matters**: Ensures we're reaching our target population

---

#### 2. **Attendance & Participation**

**What**: Who's attending and how regularly

**Indicators**:

- Session attendance numbers
- Attendance rate (% of registered attending)
- Retention rate (% completing program)
- Drop-out rate and timing
- Engagement level (active participation vs. passive attendance)

**Why it matters**: Indicates program appeal and participant commitment

---

#### 3. **Service Delivery / Fidelity**

**What**: Are we delivering what we planned

**Indicators**:

- Number of sessions delivered vs. planned
- Content covered vs. planned curriculum
- Peer worker hours delivered
- Resources distributed
- Fidelity to program model (doing what we said we'd do)

**Why it matters**: Ensures quality and consistency with approved design

---

#### 4. **Referrals & Linkages**

**What**: Connections to other services

**Indicators**:

- Number of referrals made (by service type)
- Number of referrals completed (participant actually connected)
- Referrals received (from partners to program)

**Why it matters**: Shows integration with service system

---

#### 5. **Partnerships**

**What**: Are partnerships functioning well

**Indicators**:

- Number of active partnerships
- Partnership activities completed
- Partner satisfaction
- Issues or conflicts arising

**Why it matters**: Strong partnerships are critical to program success

---

#### 6. **Participant Feedback**

**What**: Are participants satisfied and finding program useful

**Indicators**:

- Session feedback scores
- Suggestions for improvement
- Complaints received and resolved
- Positive feedback/testimonials

**Why it matters**: Real-time participant voice guides adaptation

---

#### 7. **Staffing & Resourcing**

**What**: Do we have the people and resources needed

**Indicators**:

- Staff/peer worker positions filled vs. vacant
- Staff/peer worker turnover
- Supervision sessions completed
- Budget spent vs. allocated
- Resource stock levels

**Why it matters**: Can't deliver without adequate resourcing

---

#### 8. **Safety & Incidents**

**What**: Is everyone safe

**Indicators**:

- Incidents reported (overdose, violence, accidents)
- Incident response adequacy
- Safety protocols followed
- Staff/volunteer wellbeing concerns

**Why it matters**: Safety is paramount

---

#### 9. **Risks & Issues**

**What**: What's going wrong or could go wrong

**Indicators**:

- Risks materialized from risk register
- New risks identified
- Issues log
- Actions taken to mitigate

**Why it matters**: Early problem identification enables early response

---

## 3. Data Collection Methods & Tools

### Attendance Records

**Tool**: Attendance Sign-In Sheet

**Collected**: Every session

**Data**:

- Participant name/ID
- Date
- Session attended
- Time in/out (if relevant)

**Responsible**: Session facilitator

**Stored**: [Location - e.g., locked cabinet, digital database]

---

### Session Logs

**Tool**: Session Log Template

**Collected**: Every session

**Data**:

- Date and session number
- Number of attendees
- Content covered
- Activities completed
- Materials/resources distributed
- Observations (engagement, issues)
- Follow-up actions needed

**Responsible**: Session facilitator

**Stored**: [Location]

---

### Participant Registration Forms

**Tool**: Registration/Intake Form

**Collected**: At enrollment

**Data**:

- Demographics (age, gender, location)
- Contact information
- How they heard about program
- Consent (data use, photo/video, information sharing)
- Baseline information (if relevant - e.g., service access, wellbeing)

**Responsible**: Program coordinator or intake staff

**Stored**: [Secure location, de-identified data separately from identifiable]

---

### Exit Surveys

**Tool**: Short Exit Survey (5-10 questions)

**Collected**: End of each session or end of program

**Data**:

- Satisfaction (1-5 scale)
- What was helpful
- What could be improved
- Will they return/recommend
- Anything else to share

**Responsible**: Facilitator distributes, participants complete

**Stored**: [Location]

---

### Referral Tracking Log

**Tool**: Referral Log Spreadsheet

**Collected**: When referrals made

**Data**:

- Participant ID (de-identified)
- Date of referral
- Service referred to
- Reason for referral
- Method (phone, in-person, email)
- Follow-up (did connection happen?)

**Responsible**: Whoever makes referral

**Stored**: [Secure location]

---

### Staffing Records

**Tool**: HR Records, Timesheets

**Collected**: Ongoing

**Data**:

- Staff/peer worker hours worked
- Vacancies and recruitment
- Supervision sessions completed
- Training completed

**Responsible**: HR/Admin

**Stored**: [HR files]

---

### Budget Tracking

**Tool**: Budget Spreadsheet/Finance System

**Collected**: Monthly

**Data**:

- Budget allocated vs. spent by category
- Invoices and payments
- Variance explanations

**Responsible**: Finance officer, Program coordinator

**Stored**: [Finance system]

---

### Incident Reports

**Tool**: Incident Report Form

**Collected**: As incidents occur

**Data**:

- Date, time, location
- Description of incident
- People involved
- Response taken
- Follow-up needed

**Responsible**: Person who witnesses/responds to incident

**Stored**: [Confidential location]

---

### Issues & Risks Log

**Tool**: Issues Log Spreadsheet

**Collected**: Ongoing

**Data**:

- Issue/risk description
- Date identified
- Severity
- Action taken
- Status (open/closed)

**Responsible**: Program coordinator

**Stored**: [Program files]

---

## 4. Monitoring Schedule

### Daily

| Activity                   | Responsible      | Tool                  |
| -------------------------- | ---------------- | --------------------- |
| Attendance recorded        | Facilitator      | Sign-in sheet         |
| Session log completed      | Facilitator      | Session log           |
| Referrals logged           | Staff/Peer worker| Referral log          |
| Incidents reported         | Witness          | Incident report       |

---

### Weekly

| Activity                           | Responsible         | Tool                  |
| ---------------------------------- | ------------------- | --------------------- |
| Attendance data entered            | Admin               | Database              |
| Participant feedback reviewed      | Program coordinator | Exit surveys          |
| Issues log updated                 | Program coordinator | Issues log            |
| Team debrief                       | Team                | Meeting notes         |

---

### Monthly

| Activity                           | Responsible         | Tool/Output           |
| ---------------------------------- | ------------------- | --------------------- |
| Monitoring data compiled           | Program coordinator | Monitoring report     |
| Budget review                      | Finance + PC        | Budget tracker        |
| Staffing review                    | HR + PC             | HR records            |
| Partnership check-in               | Program coordinator | Meeting notes         |
| Risk register review               | Program coordinator | Risk register         |

---

### Quarterly

| Activity                           | Responsible         | Tool/Output           |
| ---------------------------------- | ------------------- | --------------------- |
| Comprehensive monitoring report    | Program coordinator | Report to management  |
| Funder report (if required)        | Program coordinator | Funder template       |
| Data quality check                 | Program coordinator | Data audit            |
| Participant demographic analysis   | Program coordinator | Demographics report   |
| Continuous improvement planning    | Team                | Action plan           |

---

### Annual

| Activity                           | Responsible         | Tool/Output           |
| ---------------------------------- | ------------------- | --------------------- |
| Annual program report              | Program coordinator | Annual report         |
| Comprehensive data analysis        | Program coordinator | Data summary          |
| Monitoring plan review & update    | Program coordinator | Updated plan          |

---

## 5. Monitoring Targets

| Indicator                          | Target                | Current Status | On Track? | Notes          |
| ---------------------------------- | --------------------- | -------------- | --------- | -------------- |
| **Reach & Recruitment**            |                       |                |           |                |
| Participants enrolled              | [Number]              | [Current]      | ☐ Y ☐ N   | [Comments]     |
| Diversity of participants          | Representative        | [Current]      | ☐ Y ☐ N   |                |
| **Attendance**                     |                       |                |           |                |
| Session attendance (average)       | [Number per session]  | [Current]      | ☐ Y ☐ N   |                |
| Attendance rate                    | 75%+                  | [Current %]    | ☐ Y ☐ N   |                |
| Retention (completion)             | 80%+                  | [Current %]    | ☐ Y ☐ N   |                |
| **Service Delivery**               |                       |                |           |                |
| Sessions delivered                 | [Number planned]      | [Delivered]    | ☐ Y ☐ N   |                |
| Curriculum fidelity                | 90%+ of content       | [Current %]    | ☐ Y ☐ N   |                |
| Peer worker hours                  | [Target hours]        | [Current]      | ☐ Y ☐ N   |                |
| Resources distributed              | [Target number]       | [Current]      | ☐ Y ☐ N   |                |
| **Referrals**                      |                       |                |           |                |
| Referrals made                     | [Target number]       | [Current]      | ☐ Y ☐ N   |                |
| Referral completion rate           | 60%+                  | [Current %]    | ☐ Y ☐ N   |                |
| **Participant Satisfaction**       |                       |                |           |                |
| Session satisfaction score         | 4.0+/5.0              | [Current]      | ☐ Y ☐ N   |                |
| Would recommend                    | 85%+                  | [Current %]    | ☐ Y ☐ N   |                |
| **Staffing**                       |                       |                |           |                |
| Positions filled                   | 100%                  | [Current %]    | ☐ Y ☐ N   |                |
| Supervision completed              | 100% (fortnightly)    | [Current %]    | ☐ Y ☐ N   |                |
| **Budget**                         |                       |                |           |                |
| Budget on track                    | Within 5% of plan     | [Variance %]   | ☐ Y ☐ N   |                |
| **Safety**                         |                       |                |           |                |
| Serious incidents                  | 0                     | [Current]      | ☐ Y ☐ N   |                |
| Incident response adequate         | 100%                  | [Current %]    | ☐ Y ☐ N   |                |

---

## 6. Data Quality Assurance

### Data Quality Principles

- **Accurate**: Data reflects reality
- **Complete**: All required fields filled
- **Consistent**: Same data recorded same way each time
- **Timely**: Data entered promptly (within 48 hours)
- **Secure**: Data stored securely, confidentially

---

### Quality Checks

**Monthly**:

- Spot check 10% of attendance records for completeness
- Check for missing session logs
- Review referral log for completion

**Quarterly**:

- Comprehensive data audit
- Check for duplicates
- Verify calculations
- Cross-check data sources

**Issues Found**: Documented and corrected

---

### Data Security

- De-identified data wherever possible
- Identifying information stored separately from program data
- Password-protected digital files
- Locked physical files
- Access limited to authorized staff
- Privacy policy followed

---

## 7. Analysis & Interpretation

### Monthly Monitoring Dashboard

**Quick visual snapshot**:

- Attendance trend (graph)
- Recruitment vs. target (progress bar)
- Budget spent vs. allocated (pie chart)
- Satisfaction scores (rating)
- Traffic light indicators (green/yellow/red) for each target

**Distributed to**: Program team, management

---

### Quarterly Monitoring Report

**Sections**:

1. **Executive Summary**: Key highlights and concerns
2. **Reach**: Demographics, recruitment, representativeness
3. **Attendance**: Trends, retention, drop-outs
4. **Delivery**: Sessions delivered, fidelity, quality
5. **Partnerships**: Referrals, collaboration, issues
6. **Participant Feedback**: Satisfaction, themes from feedback
7. **Resources**: Budget, staffing
8. **Risks & Issues**: What's emerging, how it's being managed
9. **Learnings & Adaptations**: What we're changing based on data
10. **Next Quarter**: Priorities and focus

**Audience**: Management, board (summary), funder (as required)

---

### Data-Driven Decision Making

**Questions to Ask**:

- What's working well? How do we know?
- What's not working? Why?
- Are we reaching who we intended?
- Are we delivering as planned?
- What adaptations are needed?
- Are we on track to meet objectives?

**Use Data To**:

- Adapt program delivery (content, timing, approach)
- Address barriers (recruitment, retention)
- Allocate resources
- Support staff (if gaps in supervision, training)
- Inform stakeholders
- Celebrate successes

---

## 8. Continuous Improvement

### Feedback Loops

**Weekly Team Debrief**:

- What worked this week?
- What challenges arose?
- What do we need to adjust?
- Quick responsive changes

**Monthly Reflection**:

- Review monitoring data
- Identify trends
- Deeper problem-solving
- Plan improvements

**Quarterly Learning**:

- Comprehensive review
- Engage advisory group for input
- Document learnings
- Update program design/monitoring plan as needed

---

### Adaptive Management

**Responsive, Not Rigid**:

- Monitor → Reflect → Adjust → Monitor (iterative cycle)
- Small tests of change (try something, see if it works)
- Learning orientation (mistakes are opportunities)

**Document Changes**:

- What we changed, when, why
- Impact of changes
- Learnings for future

---

## 9. Reporting

### Internal Reporting

**To Program Team**:

- Weekly: Verbal update in team meeting
- Monthly: Dashboard shared

**To Management**:

- Monthly: Brief email update
- Quarterly: Written report
- Annual: Comprehensive report

**To Board**:

- Quarterly: Summary in management report
- Annual: Full program report

---

### External Reporting

**To Funder**:

- As per contract (typically quarterly interim, final at end)
- Use funder template
- Monitoring data informs reporting
- Narrative + data

**To Community**:

- Annual plain language report
- Social media updates (monthly)
- Community forum (annual)

**To Partners**:

- Quarterly update email
- Data sharing as per MOU (aggregated, de-identified)

---

## 10. Tools & Templates

### Monitoring Tools Repository

**All tools available at**: [Location - shared drive folder]

**Tools**:

1. Attendance Sign-In Sheet (printable)
2. Session Log Template (Word/digital)
3. Registration/Intake Form
4. Exit Survey (paper & online)
5. Referral Tracking Log (Excel)
6. Incident Report Form
7. Issues & Risks Log (Excel)
8. Monthly Monitoring Dashboard Template (Excel with graphs)
9. Quarterly Report Template (Word)

**Training**: All staff trained in data collection tools during onboarding

---

## 11. Roles & Responsibilities

| Role                   | Monitoring Responsibilities                                           |
| ---------------------- | --------------------------------------------------------------------- |
| Program Coordinator    | Overall monitoring coordination, data compilation, reporting, analysis|
| Facilitators           | Attendance, session logs, session feedback, incidents                 |
| Peer Workers           | Attendance, referral logs, participant feedback                       |
| Admin Support          | Data entry, filing, distribution tracking                             |
| Finance Officer        | Budget monitoring, financial reports                                  |
| Management             | Review reports, support data-driven decisions                         |

**Everyone**: Report incidents, contribute to continuous improvement

---

## 12. Budget for Monitoring

| Item                            | Cost        | Notes                              |
| ------------------------------- | ----------- | ---------------------------------- |
| Staff time (data entry/analysis)| $[Amount]   | [% of Program Coordinator FTE]     |
| Software/tools                  | $[Amount]   | Database, survey tool, Excel       |
| Printing                        | $[Amount]   | Forms, surveys                     |
| Participant incentives (surveys)| $[Amount]   | $[amount] x [number]               |
| Training                        | $[Amount]   | Staff training on data collection  |
| **Total**                       | **$[Total]**|                                    |

**% of Total Program Budget**: [Typically 2-5% for monitoring, more for full evaluation]

---

## 13. Limitations & Challenges

**Known Limitations**:

- Self-report data (participant surveys) - potential bias
- Small sample size - limited generalizability
- Attendance may not equal engagement
- Monitoring can't answer "why" - need evaluation for that

**Challenges to Monitor**:

- Chaotic lives mean inconsistent attendance (hard to track)
- Privacy concerns limit what data we can collect
- Staff capacity for data entry
- Participant survey fatigue

**How We Address**:

- Triangulate multiple data sources
- Keep data collection simple and minimal
- Build data collection into existing processes
- Value qualitative alongside quantitative

---

## 14. Ethics & Privacy

**Ethical Monitoring**:

- Informed consent for data collection
- Confidentiality protected
- De-identification
- Data used only for agreed purposes
- Participants can opt out of data collection (but not participation)
- Access to their own data if requested

**Mandatory Reporting**:

- Limits of confidentiality explained
- Monitoring may identify mandatory reporting situations
- Protocols in place

---

## 15. Review & Version Control

**Monitoring Plan Review**:

- Quarterly: Check if tools and targets still appropriate
- Annual: Comprehensive review and update

**Version Control**:

| Version | Date   | Changes                        | Updated By |
| ------- | ------ | ------------------------------ | ---------- |
| 1.0     | [Date] | Initial monitoring plan        | [Name]     |

---

**Effective monitoring ensures we deliver quality programs that meet community needs. This plan makes monitoring systematic, manageable, and useful.**
